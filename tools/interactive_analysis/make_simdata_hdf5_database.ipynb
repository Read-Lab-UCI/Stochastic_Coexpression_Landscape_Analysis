{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tables as pyt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import scipy.io as sio\n",
    "\n",
    "from numpy import inf\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn import decomposition \n",
    "from module_tools import get_file_paths\n",
    "from module_tools import system_entropy # calc_system_entropy\n",
    "\n",
    "%matplotlib inline  \n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation data and target trial folders\n",
    "trial_path = os.path.join('/', 'Users', 'camerongallivan', 'Research_Data', 'Simulation_Data_Py', 'Trial_0001-py')\n",
    "\n",
    "# Path to save the hdf5 file to\n",
    "output_path = os.path.join(trial_path, 'Analysis', 'PCA')\n",
    "hdf5_outputpath = os.path.join(output_path, 'simdata.h5')\n",
    "\n",
    "pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob2d(probvec, dimensions, dimensions_to_reduce=(2,3)):\n",
    "    prob_full_d = probvec.reshape(dimensions, order='F')  # Collapses probability along all system dimensions\n",
    "    prob_2d = np.sum(prob_full_d, axis=dimensions_to_reduce)  # Reduces probability to two dimensions\n",
    "    return prob_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating HDF5 Database"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For each trial the database contains:\n",
    "-The generated model name\n",
    "-The parameter values simulated\n",
    "-The Dimensions of all Rate Matrices\n",
    "-Each parameter set's:\n",
    " -Reshaped Prob2D Vector (specific for PCA analysis)\n",
    " -ProbVec's Shannon's Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camerongallivan/anaconda3/envs/Hybrid_PBN/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/camerongallivan/anaconda3/envs/Hybrid_PBN/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in log\n",
      "/Users/camerongallivan/anaconda3/envs/Hybrid_PBN/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/camerongallivan/anaconda3/envs/Hybrid_PBN/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/camerongallivan/anaconda3/envs/Hybrid_PBN/lib/python3.6/site-packages/ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "# Creating hdf5 file\n",
    "h5file = pyt.open_file(hdf5_outputpath, title='Simulation Trial Data', mode='w')\n",
    "\n",
    "data_name = 'Simulation_Data'\n",
    "results_group = h5file.create_group('/', data_name)\n",
    "\n",
    "# Assigning Paths\n",
    "trial_paths, parameters_df, simulation_files = get_file_paths.generate_trial_paths(trial_path)\n",
    "total_sets = parameters_df.index[-1]\n",
    "prob_vec_path = trial_paths['probvec']\n",
    "rate_matrix_path = trial_paths['ratematrix']\n",
    "\n",
    "# Loading and saving parameters, model name, dimensions, entropy and prob2D\n",
    "parameters_df.to_hdf(hdf5_outputpath, '/'+data_name+'/paramValues')\n",
    "results_group._v_title = 'Parameter Values saved with pd.to_hdf'\n",
    "\n",
    "dimensions = sio.loadmat(rate_matrix_path + simulation_files[0])['Dimensions'][0]\n",
    "results_group._v_attrs.dimensions = dimensions\n",
    "\n",
    "phenotype_count = dimensions[0:2].prod()\n",
    "microstate_count = dimensions.prod()\n",
    "\n",
    "probvec_array = np.empty((total_sets, microstate_count))\n",
    "prob_2d_vector_array = np.empty((total_sets, phenotype_count))\n",
    "\n",
    "for i, input_file in enumerate(simulation_files):\n",
    "    prob_vec = sio.loadmat(prob_vec_path + input_file)['ProbVec']\n",
    "    probvec_array[i] = prob_vec[0]    \n",
    "    prob_2d = calc_prob2d(prob_vec, dimensions)\n",
    "    prob_2d_vector = prob_2d.reshape(phenotype_count)\n",
    "    prob_2d_vector_array[i] = prob_2d_vector\n",
    "\n",
    "system_probvec_entropies = np.real(-np.sum(np.multiply(probvec_array, np.log(probvec_array)), axis=1))\n",
    "system_probvec_entropies = np.nan_to_num(system_probvec_entropies)\n",
    "\n",
    "prob_2d_vectors = np.abs(prob_2d_vector_array)\n",
    "system_prob2d_entropies = np.real(-np.sum(np.multiply(prob_2d_vectors, np.log(prob_2d_vectors)), axis=1))\n",
    "\n",
    "h5file.create_array(results_group, 'prob_2d_vector_array', prob_2d_vector_array, \"Prob2D Vectorized Array\")\n",
    "h5file.create_array(results_group, 'system_probvec_entropies', system_probvec_entropies, \"Shannon's Entropy of ProbVec\")\n",
    "h5file.create_array(results_group, 'system_prob2d_entropies', system_prob2d_entropies, \"Shannon's Entropy of Prob2D\")\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking HDF5 file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = pyt.open_file(hdf5_outputpath, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/camerongallivan/Research_Data/Simulation_Data_Py/Trial_0001-py/Analysis/PCA/simdata.h5 (File) 'Simulation Trial Data'\n",
      "Last modif.: 'Sat Mar  9 13:52:10 2019'\n",
      "Object Tree: \n",
      "/ (RootGroup) 'Simulation Trial Data'\n",
      "/Simulation_Data (Group) 'Parameter Values saved with pd.to_hdf'\n",
      "/Simulation_Data/prob_2d_vector_array (Array(4096, 441)) 'Prob2D Vectorized Array'\n",
      "/Simulation_Data/system_prob2d_entropies (Array(4096,)) \"Shannon's Entropy of Prob2D\"\n",
      "/Simulation_Data/system_probvec_entropies (Array(4096,)) \"Shannon's Entropy of ProbVec\"\n",
      "/Simulation_Data/paramValues (Group) ''\n",
      "/Simulation_Data/paramValues/axis0 (Array(10,)) ''\n",
      "/Simulation_Data/paramValues/axis1 (Array(4096,)) ''\n",
      "/Simulation_Data/paramValues/block0_items (Array(8,)) ''\n",
      "/Simulation_Data/paramValues/block0_values (Array(4096, 8)) ''\n",
      "/Simulation_Data/paramValues/block1_items (Array(2,)) ''\n",
      "/Simulation_Data/paramValues/block1_values (Array(4096, 2)) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) 'Simulation Trial Data'\n",
      "/Simulation_Data (Group) 'Parameter Values saved with pd.to_hdf'\n",
      "\n",
      "/Simulation_Data (Group) 'Parameter Values saved with pd.to_hdf'\n",
      "/Simulation_Data/paramValues (Group) ''\n",
      "/Simulation_Data/prob_2d_vector_array (Array(4096, 441)) 'Prob2D Vectorized Array'\n",
      "/Simulation_Data/system_prob2d_entropies (Array(4096,)) \"Shannon's Entropy of Prob2D\"\n",
      "/Simulation_Data/system_probvec_entropies (Array(4096,)) \"Shannon's Entropy of ProbVec\"\n",
      "\n",
      "/Simulation_Data/paramValues (Group) ''\n",
      "/Simulation_Data/paramValues/axis0 (Array(10,)) ''\n",
      "/Simulation_Data/paramValues/axis1 (Array(4096,)) ''\n",
      "/Simulation_Data/paramValues/block0_items (Array(8,)) ''\n",
      "/Simulation_Data/paramValues/block0_values (Array(4096, 8)) ''\n",
      "/Simulation_Data/paramValues/block1_items (Array(2,)) ''\n",
      "/Simulation_Data/paramValues/block1_values (Array(4096, 2)) ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in h5file.walk_groups():\n",
    "    print(group)\n",
    "    for val in group.__iter__():\n",
    "        print(val)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
